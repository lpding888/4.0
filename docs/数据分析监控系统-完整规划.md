# 数据分析与监控系统 - 完整规划方案

> 本文档提供可直接投入实施的数据分析与监控系统规划。整体内容分为三部分：**架构设计**、**任务卡拆分**、**实施路线图**。

---

## 第一部分：数据分析系统架构设计

### 1. 指标体系设计（口径、维度与方法）

#### 1.1 指标分层（KPI/KSI/诊断指标）

* **北极星/核心 KPI**：DAU、7D/30D 留存、任务成功率、GMV、ARPU、会员续费率、渠道付费转化率（注册→付费）、API p95 响应时延、错误率。
* **KSI（关键成功指标）**：功能使用渗透率（抠图/换装等）、付费用户占比、配额退款率、客服满意度（CSAT）、任务失败 Top 原因占比、营销活动 ROI、QPS 上限利用率。
* **诊断指标（维持健康）**：各端 PV/UV、会话时长、事件转化率、订单结构、地域/设备分布、异常类型分布、服务器资源使用（CPU/内存/磁盘/带宽/GPU）。

#### 1.2 指标口径定义

**用户类指标：**

* **注册用户数**：当日成功注册且完成手机号/邮箱验证的去重 `user_id` 数。
* **DAU/MAU**：当日/当月产生任意有效事件（登录/任务/下单等）的去重 `user_id`。
* **留存率**：基于**注册 Cohort**。`次日留存 = 第 T 天注册用户中在 T+1 天仍活跃的用户数 / 第 T 天注册用户数`；同理 7/30 日留存。需排除异常账号。
* **流失率**：`在观察窗口内连续 N 天（建议 14/30 天）无活跃且之前活跃过的用户 / 窗口开始时活跃用户`。
* **用户画像**：年龄、性别、地域（国家/省/市）、职业、设备、渠道、首购价位、偏好功能。画像来自用户注册信息 + 行为聚合 + 订单。
* **LTV（生命周期价值）**：`LTV(t)= Σ_{τ=0..t} (ARPU_cohort(τ) × Survival(τ))`，可按月贴现率 d 折现（可选）。

**业务类指标：**

* **任务总数/成功率/失败率**：任务以 `task_id` 唯一；`成功率 = 成功任务数 / 提交任务总数`。失败需按**错误码**归类（模型异常/超时/余额不足/用户取消等）。
* **功能使用率**：按功能枚举（抠图/消除笔/换装/换脸/扩图…），`功能使用渗透 = 使用该功能的活跃用户 / DAU`；`功能调用占比 = 功能任务数/总任务数`。
* **配额消耗/退款率**：`配额消耗 = Σ(本期扣减配额)`；`退款率 = 退款订单数 / 支付订单数` 或 `退款金额 / 支付金额`（两口径需同时保留）。
* **会员购买率/续费率**：`会员购买率 = 当期新增会员人数 / 新增付费用户数`；`续费率 = 到期应续费人数中完成续费的人数 / 到期应续费人数`。
* **订单金额/GMV**：含会员、单次购买、增购配额；GMV 为支付金额总和（含优惠后实际到款）。
* **付费用户占比**：`当期产生支付的去重用户 / 活跃用户`；**ARPU**：`GMV / 活跃用户数`；**ARPPU**：`GMV / 付费用户数`。

**运营类指标：**

* **渠道分析**：来源（自然/应用商店/广告/联运/活动），`注册转化率 = 注册数 / 渠道 UV`，`付费转化率 = 付费人数 / 注册数`，`CAC = 渠道花费 / 新增付费人数`。
* **营销活动效果**：参与率、转化率、客单价提升、留存提升、ROI=`(活动带来增量 GMV-成本)/成本`。
* **客服/满意度**：工单量、首响时长、解决时长、一次解决率（FCR）、CSAT（1~5 或 NPS）。

**技术类指标：**

* **API 响应时间**：p50/p90/p95/p99，区分读写接口与模型推理接口。
* **吞吐（QPS）**：峰值/平均。
* **错误率/异常率**：5xx 比例、超时比例、业务错误码分布。
* **资源使用**：CPU/内存/磁盘/带宽/GPU 利用率，队列堆积，缓存命中率。

#### 1.3 维度体系

* **时间**：日期、小时、周、月；本期/环比/同比。
* **用户**：user_id、新/老（7/30/90 日回访）、会员等级、付费段（RFM）。
* **渠道**：channel、campaign、ad_group、creative、utm_*。
* **功能**：feature（抠图/换装/…）、版本、端（Web/iOS/Android/API）。
* **地域/设备**：国家/省/市、设备品牌/型号、系统/浏览器。
* **技术**：接口名、错误码、实例/容器、可用区。

#### 1.4 方法论与分析范式

* **漏斗**（注册→体验→付费→复购），支持跨天漏斗与回溯窗口。
* **Cohort**（按注册周/首购月），对比留存/LTV/ARPU。
* **路径分析/队列分析**：最短成功路径、流失节点 Top-K。
* **归因**：首次接触/最后接触/时间衰减；广告 MMP 数据对接。
* **分群**：规则分群（画像 + 行为），模型分群（KMeans/二分类流失预测）。
* **效应评估**：A/B 实验（CUPED/贝叶斯）评估功能上线与活动 ROI。

---

### 2. 数据采集方案

#### 2.1 埋点设计

**公共字段（必须）**：
- event_time(ms)、event_date、event_name、event_version
- user_id、device_id、session_id、platform、app_version
- country/province/city、network、page_id、referrer
- channel/campaign/utm_*、feature、ab_bucket
- request_id、trace_id、ip_hash（加盐哈希）

**页面浏览（PV/UV）**：`page_view`；进入/离开、停留时长、首屏时间、曝光区域。

**事件埋点**：
- 点击（`click_xxx`）
- 提交（`submit_xxx`）
- 分享（`share_xxx`）
- 功能调用（`feature_invoke` 带 `feature=remove_bg/…`）
- 下单（`place_order`）
- 支付（`pay_success`/`pay_refund`）

**性能埋点**：`perf_page`（TTFB、FCP、LCP、CLS）、`perf_api`（latency、status）、`perf_task`（排队时间/推理时长/重试次数）。

**错误埋点**：前端 `js_error`、后端 `api_error`、任务 `task_fail`（含错误码）。

**隐私与合规**：不采集明文手机号/邮箱；PII 必须脱敏、加密存储；提供"拒绝追踪"与 Cookie 同意管理（CMP）。

#### 2.2 前后端采集链路

* **前端 SDK**（Web/小程序/移动端）：自动采集 PV、性能、错误；手动 API 发送业务事件；本地缓存/批量上报；幂等 `event_id`；离线重传。
* **后端中间件**：HTTP/GRPC 拦截器埋点（响应时延、状态码、上下游 trace），统一上报。
* **传输层**：Nginx/Gateway → **Kafka/Pulsar**（Topic 按事件域分区）→ Schema Registry（Avro/JSON Schema）。
* **实时处理**：Flink/Kafka Streams 做清洗、去重（`event_id` + 5m 窗口）、维表（渠道/功能映射）、指标窗口聚合（1m/5m）。
* **批处理**：Airflow + Spark/SQL，T+1 生成宽表、Cohort 表、留存与 LTV 表。
* **日志侧链**：Fluent Bit/Vector → Kafka → S3/HDFS（原始日志）→ ELK/Grafana Loki（检索与排障）。

#### 2.3 数据质量与治理

* **质量规则**：完整性（必填字段非空）、唯一性（`event_id` 去重率<0.1%）、及时性（延迟<5m/15m/24h）、一致性（维度映射命中率>99.5%）、准确性（抽样回放）。
* **监控**：Great Expectations/Deequ 定义规则，异常触发告警到钉钉/邮件。
* **版本管理**：`event_version` 升级不破坏兼容，Schema Registry 强约束。
* **血缘与字典**：Amundsen/DataHub + Git 存储字典与任务血缘图。

---

### 3. 数仓建模与存储

#### 3.1 分层与命名

* **ODS**（原始层）：事件原始表，分区 `dt/hour`，保留 180 天。
* **DWD**（明细层）：宽事件表（去重清洗），如 `dwd_event_app`。
* **DWM**（中间聚合）：分钟/小时聚合，如 `dwm_user_active_1h`、`dwm_task_perf_5m`。
* **DWS**（服务层）：分析主题表，如 `dws_user_retention_1d`、`dws_funnel_register_pay_1d`。
* **ADS**（应用层）：给大屏/报表/接口用的宽表/Materialized View。
* **维表**：`dim_user`、`dim_channel`、`dim_feature`、`dim_geo`、`dim_device`、`dim_error_code`、`dim_api`。

#### 3.2 事实表示例

* `fact_user_active_1d(user_id, first_seen_date, is_new, dau_flag, sessions, features_used, pay_flag, arpu)`
* `fact_task(feature, task_id, user_id, status, error_code, queue_ms, infer_ms, total_ms, quota_cost, ts)`
* `fact_order(order_id, user_id, amount, discount, pay_amount, pay_status, refund_amount, product_type, ts)`
* `fact_marketing(campaign_id, cost, impressions, clicks, installs, regs, pays, revenue, ts)`

#### 3.3 存储与引擎选型

* **实时查询**：ClickHouse/Pinot/StarRocks（二选一），支撑近 90 天明细与秒级聚合；冷热分层存储（S3 + 本地盘）。
* **离线存储**：S3/HDFS + Parquet；计算 Spark/Trino/Presto。
* **在线应用数据**：MySQL/PolarDB（订单、账户、配额变更账本）。
* **缓存与排行榜**：Redis（HyperLogLog 去重、TopN、Counter），TTL 控制 1~7 天。
* **日志检索**：ELK/Loki；时序与基础指标 Prometheus + VictoriaMetrics。

#### 3.4 性能与成本

* 关键表 **MergeTree**（CH）按 `(dt, feature, user_id)` 排序，启用物化视图做预聚合；典型查询 QPS 目标 50+，p95<300ms。
* 大屏指标走 Redis 或物化视图；复杂视图离线异步刷新，避免直查明细高并发。
* 全链路压测：Kafka 吞吐≥ 50MB/s、ClickHouse 导入≥ 10M 行/分、OLAP 并发≥ 100。

---

### 4. 可视化与交互设计

#### 4.1 实时监控大屏

* **首屏 KPI 卡片**：DAU、任务成功率、当前 QPS、p95 延迟、错误率、当日 GMV、活动转化率。
* **趋势**：DAU/GMV/成功率分钟线；关键接口 p95 趋势。
* **分布**：功能占比（环图）、渠道转化（柱状）、错误码 Top10（条形）。
* **告警区**：近 24h 告警流，点击跳转到日志与指标详情。

#### 4.2 分析页面

* **用户分析**：新增/活跃、Cohort 留存（热力图）、流失回补（召回活动反馈）、分群导出（CSV）。
* **业务分析**：功能渗透与粘性、任务耗时分布、失败原因钻取、配额消耗-收入联动。
* **运营分析**：渠道漏斗（曝光→点击→注册→付费）、活动 A/B、ROI 看板。
* **技术运维**：接口 SLI（可用性/时延/错误率）、实例资源、任务积压、慢查询。

#### 4.3 交互与组件

* 统一筛选：时间、渠道、地域、端、功能、版本、用户分群。
* 对比模式：环比/同比、对照组对比。
* 导出：Excel/CSV；一键截图/分享抽屉。
* 权限：**RBAC + 行级权限**（按部门/渠道/地区/客户经理隔离）。
* 组件：折线/面积、柱状/条形、饼/环、漏斗、桑基（路径）、热力（留存）、箱线（时延）、表格。

---

### 5. 安全合规与访问控制

* **分级数据**：PII（手机号/邮箱）— 强加密、脱敏展示；行为明细—按最小权限需求开放；汇总指标—默认可见。
* **访问策略**：OAuth/SSO；审计日志；下载水印与操作留痕；外链分享时效与令牌。
* **合规**：GDPR/CCPA 关键点（同意、可删除请求、目的限制、数据最小化）；数据跨境需要合规评估与网关脱敏。

---

### 6. SLA/SLO 与告警策略

* **数据层**：实时指标 T+1m、延迟告警阈值 5m；离线 T+1 8:30 全量产出。
* **服务层**：大屏可用性 ≥ 99.9%；关键查询 p95 < 500ms；导出任务 99% < 2 分钟。
* **告警**：静态阈值 + 自适应基线（EWMA/季节性分解）；多渠道（钉钉、邮箱、短信），分级（P0/P1/P2），抖动抑制与合并策略。

---

### 7. 质量保障与灰度

* **数据回放**：灰度 5% 用户，上报双通道比对（SDK 新旧版本）。
* **幂等/去重**：`event_id` + 窗口去重；任务侧 `task_id` 全局唯一。
* **自动化测试**：埋点单测+端到端集成（模拟事件→OLAP 查询比对）。
* **回归审计**：口径变更走变更单与双跑周期，变更后 7 日跟踪误差<0.5%。

---

## 第二部分：实施路线图

### Phase 0（准备日，Kickoff + 基线评估，D-2 ~ D0）

* **对齐范围**：最终看板内容、KPI 列表、口径定义、权限矩阵、合规边界。
* **环境准备**：Kafka/OLAP 集群建好，Schema Registry/Prometheus/ELK 基础服务可用。
* **基线抓取**：现有日志与订单导入样本，评估数据缺口与脏数据比例。
* **风险预案**：明确回滚策略（关埋点开关、降级到离线报表）。

### Phase 1（Week 1：数据采集与传输闭环）

* **交付项**：埋点白皮书 v1、前端/后端 SDK 灰度、上报 API、清洗与 DWD、Redis 实时聚合。
* **关键路径**：
  1. 完成埋点方案设计、前端/后端SDK开发、上报API
  2. 跑通数据清洗（ODS→DWD）
  3. 建立 Redis 近实时指标（DAU 近似、成功率、错误 Top）
* **风险控制**：SDK 灰度 5% 流量；Kafka 回压与多副本；事件版本兼容。
* **里程碑**：第 5 天形成数据探查报告与质量看板（完整率、去重率、延迟）。

### Phase 2（Week 2：数据分析产出与口径固化）

* **交付项**：用户增长/留存 Cohort 表、漏斗与路径计算表、收入/配额/功能主题表。
* **完成任务**：用户分析、流失分析、画像分群、功能分析、配额分析、收入分析、渠道归因。
* **引入**：实验评估模板与样本量计算，为 Week3 的运营分析页做准备。
* **验收**：对 5 个核心指标（DAU、任务成功率、GMV、7D 留存、API p95）做双跑比对，误差<0.5%。

### Phase 3（Week 3：可视化上线与权限闭环）

* **交付项**：实时大屏、用户分析页、业务分析页、运营分析页、图表库、导出、权限。
* **关键要求**：秒级响应、缓存/预聚合命中率>85%；行级权限可回归测试通过。
* **联调**：看板跳转→日志检索；导出任务→下载中心→审计可追溯。

### Phase 4（Week 4：告警与自动报表）

* **交付项**：异常告警、业务告警、日报/周报/月报。
* **运维**：告警分级（P0 系统级，P1 业务核心，P2 一般），值班与演练（拨测 + 注入故障）。
* **观测**：误报/漏报率连续 3 天达标；报表 8:30 之前稳定送达；周报自动写作与人工二审机制跑通。

---

## 第三部分：验收标准

1. **实时监控大屏可查看关键指标**
   - DAU/任务成功率/GMV/QPS/p95/错误率 实时刷新
   - 首屏<3s，查询 p95<500ms

2. **用户分析页面可查看用户增长、留存、流失**
   - Cohort 热力、分群导出
   - 留存口径与字典一致
   - 导出稳定>99%

3. **业务分析页面可查看功能使用、配额消耗、收入统计**
   - 功能渗透/成功率、失败码钻取
   - 配额-产出效率、订单结构与 ARPU 可对比

4. **异常指标自动告警（钉钉/邮件）**
   - 任务成功率/错误率/时延异常
   - 合并与抑制策略降低噪声>40%
   - 平均确认<5 分钟

5. **日报/周报/月报自动生成**
   - 日报 8:30 前投递
   - 周报含变化解释与建议
   - 月报含结构诊断与下月行动项

---

## 补充：技术选型建议

* **OLAP 首选**：ClickHouse（Materialized View + Summing/AggregatingMergeTree）；或 StarRocks/BigQuery。
* **实时引擎**：Flink 适合复杂窗口与维表 Join；轻量场景 Kafka Streams 即可。
* **指标服务**：将口径与 SQL 封装为服务（Metrics-as-Code），版本化管理。
* **成本优化**：冷热分层、TTL、列裁剪；导出采用分片流式；日志生命周期管理（30/90/180 天档）。
* **隐私合规**：PII 加密、IP Hash、最小化采集；对外分享默认脱敏；导出带水印与审计。

---

## 任务卡清单

详细的29张任务卡（18字段标准格式）已按角色分组，存放在 `tasks/data-analysis-system/` 目录。

**任务卡分组：**
- 数据产品经理（1张）
- 前端工程师（7张）
- 后端工程师（4张）
- 数据工程师（3张）
- 数据分析师（10张）
- 数据科学家（2张）
- SRE（1张）
- 数据平台工程师（1张）

**共计29张任务卡，覆盖数据采集、分析、可视化、告警报表全流程。**
